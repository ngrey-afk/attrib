import subprocess
import textwrap
import datetime
import re


def call_ollama(model: str, prompt: str, timeout: int = 120) -> str:
    """–í—ã–∑—ã–≤–∞–µ—Ç –ª–æ–∫–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å Ollama –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä–æ–∫–æ–≤—ã–π –æ—Ç–≤–µ—Ç."""
    try:
        result = subprocess.run(
            ["ollama", "run", model],
            input=prompt.encode("utf-8"),
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            timeout=timeout,
            check=True
        )
        return result.stdout.decode("utf-8").strip()
    except subprocess.TimeoutExpired:
        print("‚ö†Ô∏è –¢–∞–π–º–∞—É—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏, –ø–æ–≤—Ç–æ—Ä...")
        return ""
    except subprocess.CalledProcessError as e:
        print("‚ùå –û—à–∏–±–∫–∞ Ollama:", e.stderr.decode("utf-8"))
        return ""


def clean_keywords(text: str) -> list[str]:
    """–ß–∏—Å—Ç–∏–º, —Ñ–∏–ª—å—Ç—Ä—É–µ–º –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞."""
    text = re.sub(r"[#*\-\n\r\.\|]+", " ", text)
    text = re.sub(r"\s+", " ", text)
    words = [w.strip().lower() for w in text.split(",") if w.strip()]
    cleaned = []
    for w in words:
        w = re.sub(r"[^\w\s-]", "", w)
        if 2 <= len(w) <= 50 and w not in cleaned:
            cleaned.append(w)
    return cleaned


def test_prompts():
    caption = "A dog wearing a Santa hat sitting on a sofa near Christmas tree"
    description = (
        "A cute dog with red hat sitting on cozy couch, festive decoration, "
        "Christmas celebration, winter holidays"
    )

    log_path = "ollama_keywords_test.txt"
    with open(log_path, "w", encoding="utf-8") as f:
        f.write(f"üß† –¢–µ—Å—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤\n{datetime.datetime.now()}\n\n")

    # –ï–î–ò–ù–´–ô –ü–†–û–ú–ü–¢
    prompt = f"""
You are generating high-quality English keywords for stock photo/video metadata.

Scene description:
"{caption}"
"{description}"

TASK:
Generate exactly 120 unique English keywords (1‚Äì3 words each) optimized for stock photo metadata on Shutterstock and Adobe Stock.
The goal is to create diverse, relevant, and commercially valuable keywords describing both the main subjects and the broader visual/emotional context.

STRUCTURE PRIORITY:
1. Start with 8‚Äì10 **commercially strong subjects** (combine object + context):
   Examples: christmas dog, festive dog, dog on sofa, cozy pet, santa hat dog, family home interior.
2. Then add 6‚Äì8 **main visual objects and their synonyms**:
   Examples: dog, puppy, pet, santa hat, christmas tree, sofa, cozy couch, living room.
3. Then 6‚Äì8 **emotional and lifestyle words**:
   Examples: joy, warmth, love, happiness, family, comfort, peace, togetherness.
4. Add 8‚Äì10 **context and atmosphere** terms:
   Examples: winter interior, cozy home, holiday decor, festive background, warm tones, soft lighting.
5. If the image clearly belongs to a holiday or event, include only **those relevant holidays** (e.g., christmas, new year, halloween).
6. Add 10‚Äì15 **artistic and technical composition words**:
   Examples: natural light, copy space, minimalist decor, close up, bokeh, texture, detail, warm background.
7. Finally, add 10‚Äì15 **short 2‚Äì3-word semantic phrases** mixing mood, style, and action:
   Examples: joyful celebration, festive atmosphere, cozy winter home, family holiday moment, creative lifestyle.

RULES:
- Prioritize the most descriptive and commercial keywords first.
- Avoid generic terms like ‚Äúphoto,‚Äù ‚Äúimage,‚Äù ‚Äústock,‚Äù or ‚Äúconcept.‚Äù
- Avoid repeating the same root more than twice (e.g., ‚Äúchristmas‚Äù only 2 times).
- Output only lowercase, comma-separated keywords in one line.
- No lists, numbering, markdown, or explanations.
- Do not invent unrelated holidays.

Output must contain **exactly 120 comma-separated keywords** in one line.



"""

    print("\n=== –¢–ï–°–¢: –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç ===")
    result = call_ollama("gemma2:2b", prompt)

    if not result:
        print("‚ö†Ô∏è –ú–æ–¥–µ–ª—å –Ω–µ –≤–µ—Ä–Ω—É–ª–∞ –æ—Ç–≤–µ—Ç.")
        return

    keywords = clean_keywords(result)

    if len(keywords) < 50:
        fill_prompt = (
            f"Generate {100 - len(keywords)} additional unique related keywords "
            f"for this topic: {caption}. Lowercase, comma-separated, 1‚Äì2 words each."
        )
        extra = call_ollama("gemma2:2b", fill_prompt)
        extra_words = clean_keywords(extra)
        keywords.extend(extra_words)
        keywords = list(dict.fromkeys(keywords))

    print(f"üü¢ –ü–æ–ª—É—á–µ–Ω–æ: {len(keywords)} —Å–ª–æ–≤")
    preview = ", ".join(keywords[:20])
    print(preview + " ...")
    print("========================================")

    with open(log_path, "a", encoding="utf-8") as f:
        f.write("=== –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç ===\n")
        f.write(f"üü¢ –ü–æ–ª—É—á–µ–Ω–æ: {len(keywords)} —Å–ª–æ–≤\n")
        for j in range(0, len(keywords), 5):
            f.write(", ".join(keywords[j:j + 5]) + "\n")
        f.write("========================================\n\n")

    print(f"\n‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª: {log_path}")


if __name__ == "__main__":
    print(textwrap.dedent("""
        ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        üß†  –¢–µ—Å—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ —á–µ—Ä–µ–∑ Ollama
        ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    """))
    test_prompts()
